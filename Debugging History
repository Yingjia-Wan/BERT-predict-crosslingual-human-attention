The main body of the project codes comes from the Github project: https://github.com/felixhultin/cross_lingual_relative_importance.
However, some modifications are made in order to get the script running:

0. modified analysis/create_plots.py: def process_tokens
line34
original:
doc = Doc(nlp.vocab, words=tokens)
modified:
doc = spacy.tokens.doc.Doc(nlp.vocab, words=tokens)


1. modifed extract_all.py
removed unnecessary BERT variants
added model paths for chinese BERT
completed: def extract_all_human_importance(corpus)

2. modified data_extractor_geco
changed the extracted columns representing the same values as in the English data

3. modified analyse_all.py
