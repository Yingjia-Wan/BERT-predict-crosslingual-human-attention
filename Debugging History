The main body of the project codes comes from the Github project: https://github.com/felixhultin/cross_lingual_relative_importance.
However, some modifications are made in order to get the script running:

0. modified analysis/create_plots.py: def process_tokens
line34
original:
doc = Doc(nlp.vocab, words=tokens)
modified:
doc = spacy.tokens.doc.Doc(nlp.vocab, words=tokens)


1. modifed extract_all.py
removed unnecessary BERT variants
added model paths for chinese BERT
completed: def extract_all_human_importance(corpus)

2. modified data_extractor_geco
changed the extracted columns representing the same values as in the English data

3. modified analyse_all.py

4. cleaned all the russian files

5. supplmented data:
python -m spacy download zh_core_web_trf
set up the geco_ch folder with two subfolders: 'raw' and relfix
put material and L1ReadingData.xlsx in the raw folder
added modelpath and corpus of geco_ch in extract_all.py and analyze_all.py
